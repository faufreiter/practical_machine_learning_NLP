{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d7bdb7-56ee-4b90-b8de-048513208478",
   "metadata": {},
   "source": [
    "# 2023S 136040-1 Practical Machine Learning for Natural Language Processing\n",
    "\n",
    "https://ufind.univie.ac.at/de/course.html?lv=136040&semester=2023S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088a84b-79a0-4b0e-84e8-471319c5a65c",
   "metadata": {},
   "source": [
    "## 02.03.2023\n",
    "\n",
    "Introduction\n",
    "\n",
    "## 07.03.2023\n",
    "\n",
    "Versioning + Github\n",
    "\n",
    "## 09.03.2023\n",
    "\n",
    "Functions, data types and scopes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0f472-5f8e-4685-ab11-e04be3220b08",
   "metadata": {},
   "source": [
    "## 14.03.2023\n",
    "### Used notebooks \n",
    "#### Python_Basic\n",
    "* 03_Functions\n",
    "* 04_Scopes\n",
    "* 05_Packages\n",
    "* 06_Comprehensions\n",
    "* 07_Functional_Programming\n",
    "\n",
    "#### Python_Intermediate\n",
    "* 09_Classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ef4cb-8fea-4251-8ecf-322782dd3a2b",
   "metadata": {},
   "source": [
    "### **04_Scopes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a01d185b-1fc0-4934-9677-0c4c1759d200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local2\n",
      "local1\n",
      "global\n"
     ]
    }
   ],
   "source": [
    "#Nested scopes in Python\n",
    "\n",
    "x = 'global'\n",
    "\n",
    "def local1():     #If another variable exists with the same name inside the function, the reference before assignment yields an error\n",
    "    #print(x)\n",
    "    x = 'local1'\n",
    "    def local2():\n",
    "        #print(x)\n",
    "        x = 'local2'\n",
    "        print(x)\n",
    "    local2()   \n",
    "    print(x)\n",
    "\n",
    "local1()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6431c6d-332c-488e-a7bc-b4ac56bf7cf5",
   "metadata": {},
   "source": [
    "--> visualize code of nested scopes via https://pythontutor.com/visualize.html#mode=display "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbbbc6-b604-4b39-8c80-2ab8496b30c8",
   "metadata": {},
   "source": [
    "### **03_Functions**\n",
    "**Generator functions (yield, next)**\n",
    " * \"stores\" value inside (\"normal\" function doesn't store value when run)\n",
    " * returns internal state while running with \"next\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b82a3-ed35-4a98-bbd7-42af785e9e2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **06_Comprehensions**\n",
    "\n",
    "*List comprehensions* --> \"Using for filtering strings\"\n",
    "* important methods for NLP\n",
    "\n",
    "*Set comprehensions*\n",
    "\n",
    "*Dict comprehensions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab026e3d-0e22-4dc9-b828-966abf702fe3",
   "metadata": {},
   "source": [
    "### **05_Packages**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0631849e-f710-4949-8f7f-6bad6b7903a6",
   "metadata": {},
   "source": [
    "### **07_Functional_Programming**\n",
    "\n",
    "*lambda Functions* --> worth exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ed529-60f9-4112-b2b6-258eb70e7690",
   "metadata": {},
   "source": [
    "--> assignment: NLP tasks like unix-shell https://www.cs.upc.edu/~padro/Unixforpoets.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6155088-bbfc-490a-8528-5135ae814818",
   "metadata": {},
   "source": [
    "### **09_Classes**\n",
    "\n",
    "* \"triple quote strings\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619b38a-d966-45b9-99b1-dce73b0ad578",
   "metadata": {},
   "source": [
    "### HOMEWORK:\n",
    "\n",
    "* classes\n",
    "* data persistance\n",
    "* functional programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c35f82-892b-400f-aede-e8fddbe4584c",
   "metadata": {},
   "source": [
    "https://dh-network.github.io/python4poets/\n",
    "\n",
    "https://web.stanford.edu/class/archive/linguist/linguist278/linguist278.1172/notes/278-UnixForPoets.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255f425-9f39-4a1a-9479-a0166d873da3",
   "metadata": {},
   "source": [
    "## 16.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb4656-fe9f-43f0-a0f9-632133f36cc3",
   "metadata": {},
   "source": [
    "* HOMEWORK 1: assignment 5 until **28.03.2023** \n",
    "* DOWNLOAD --> NLTK\n",
    "* exercises (classes): quizzes/assignments in \"Python Course\", (Renato's repository)\n",
    "\n",
    "### **09_Classes**\n",
    "\n",
    "* init() method\n",
    "* super \n",
    "* subclasses\n",
    "* inheritance\n",
    "* modifying class\n",
    "* add class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0a158-477c-45f3-83a1-12896b2ffad5",
   "metadata": {},
   "source": [
    "## 21.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda4df7-e86c-4a6a-95cc-73a742052a3d",
   "metadata": {},
   "source": [
    "### **12_Unitary_Tests**\n",
    "\n",
    "### **10_Decorators**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20be9079-cd79-4eb1-8db5-7435480698c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def not_during_the_night(func):\n",
    "    def wrapper():\n",
    "        if 7 <= datetime.now().hour < 22:\n",
    "            func()\n",
    "        else:\n",
    "            pass  # Hush, the neighbors are asleep\n",
    "    return wrapper\n",
    "\n",
    "def say_whee():\n",
    "    print(\"Whee!\")\n",
    "\n",
    "say_whee = not_during_the_night(say_whee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb899778-53cf-4c88-b4ff-4691f72b4b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whee!\n"
     ]
    }
   ],
   "source": [
    "say_whee()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c3c5cd-383d-4a45-a183-feaad044db10",
   "metadata": {},
   "source": [
    "#### Decorator template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b68cb9-6a71-4aca-90d3-e0e9765d8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def decorator(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_decorator(*args, **kwargs):\n",
    "        # Do something before\n",
    "        value = func(*args, **kwargs)\n",
    "        # Do something after\n",
    "        return value\n",
    "    return wrapper_decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef2657-665a-4d17-bb95-e179046ec785",
   "metadata": {},
   "source": [
    "### 23.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6dd447-af5e-4ad1-b6d4-f1a763299bf6",
   "metadata": {},
   "source": [
    "### **Introduction to Text Representation for ML**\n",
    "--> Representing text with vectory\n",
    "\n",
    "### **Python_DataScience**\n",
    "### 01_Intro_Numpy\n",
    "### 12_Unitary_Tests\n",
    "\n",
    "#### 2nd assignment: 15.04.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620114d-3b89-4a80-9b3d-0d24ec1cde9b",
   "metadata": {},
   "source": [
    "https://icolorpalette.com/color/ddd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88685844-8aba-466e-b9b8-c67ab48b872d",
   "metadata": {},
   "source": [
    "# 28.03.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251f387-3423-4af7-926d-f8b2057583d1",
   "metadata": {},
   "source": [
    "### **scikit-learn**\n",
    "\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "### **DataScience_Course**\n",
    "### 1a_IntroNLP_TextClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32caa9-f060-4bbb-a58b-4876f5ace7df",
   "metadata": {},
   "source": [
    "# 25.04.2023\n",
    "* Neural Network - Notebook (Renato)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a25f2-67b8-4345-bff3-2b59be859232",
   "metadata": {},
   "source": [
    "# 27.04.2023\n",
    "\n",
    "* Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2a953-34fb-4d4d-907c-1e71e3eb02a3",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "**Was ist der Wert von b?**\n",
    "\n",
    "a = np . a r a n g e ( 4 ) --> a: [0, 1, 2, 3]\n",
    "\n",
    "b = a [ : ] --> b: [0, 1, 2, 3]\n",
    "\n",
    "a ∗= b --> a = a*b ; a: [0, 1, 4, 9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9590b-f334-461b-b9ee-86fc20967db8",
   "metadata": {},
   "source": [
    "#### Speicherplatz\n",
    "\n",
    "**Gegeben:**\n",
    "* 1000 Dokumente\n",
    "* 100 verschiedene Wörter pro Dokument\n",
    "* 10000 Vokabulargröße\n",
    "Wieviel Speicherplatz (Prozent) ben ̈otigt eine Sparse Matrix im\n",
    "Vergleich zu einem Array?\n",
    "\n",
    "Numpy/dense: 1000 * 10 000 = 10 000 000\n",
    "\n",
    "Sparse: 1000 * 100 * 3 = 300 000 \n",
    "\n",
    "(row, col) --> value (--> * 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82306cd-76c7-4b18-9f85-2a93745ccff5",
   "metadata": {},
   "source": [
    "# 02.05.2023\n",
    "\n",
    "* prompt engineering Chat GPT: https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\n",
    "\n",
    "## Scikit-Learn\n",
    "* DictVectorizer\n",
    "* CountVectorizer\n",
    "* TfidfVectorizer https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html --> NOT part of the lecture slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302c3c3-f553-4922-af2f-a7d1e8f9f4f7",
   "metadata": {},
   "source": [
    "# 04.05.2023\n",
    "\n",
    "* MaxEnt Classifier\n",
    "* NLTK documentation https://www.nltk.org/_modules/nltk/classify/maxent.html\n",
    "* Scikit-Learn LogisticRegression https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* Support-Vector Machine https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa80bd9-a5f7-4ded-a211-8612a3cb3009",
   "metadata": {},
   "source": [
    "# 09.05.2023\n",
    "### linear regression:\n",
    "\n",
    "\n",
    "\n",
    "### gradient descent:\n",
    "\n",
    "* numerical algorithm, approximates numerically; often more stable and faster\n",
    "\n",
    "* you could be stuck in a local minimum, optimization algorithim --> finding minimums (topology of the function important)\n",
    "\n",
    "* *scaling of features*: important for the results, could deform the topology of the algorithm and change the outcome\n",
    "\n",
    "\n",
    "\n",
    "### MaxEnt Classifier\n",
    "\n",
    "\n",
    "* testing the function of algorithm: https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=xor&regDataset=reg-gauss&learningRate=0.03&regularizationRate=0&noise=0&networkShape=1&seed=0.40806&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac48411-64e2-4aa0-8bf2-64d2ddb70517",
   "metadata": {},
   "source": [
    "# 11.05.2023\n",
    "\n",
    "# 16.05.2023\n",
    "\n",
    "* *fit*: Learn a list of feature name -> indices mappings. (maybe if you just want to define the features, vectorizer remembers this assignment); if no vectorizer given it needs to be fitted\n",
    "* *transform*: list of dicts to matrix; if vectorizer already available --> transform\n",
    "* *fit_transform*: fit + transfrorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d864b153-cb34-497d-81eb-5eb03ec8c85a",
   "metadata": {},
   "source": [
    "# 23.05.2023\n",
    "\n",
    "* Abschlussprüfung: moodle quizzes, code\n",
    "* WH: MaxEnt\n",
    "* questions: cosine similarity\n",
    "* dot product without numpy (coding question)\n",
    "\n",
    "## Besprechung moodle quizzes\n",
    "\n",
    "* SoftMax-Funktion p(apple|x) = ...\n",
    "* Likelihood\n",
    "* Question 5: a, b, c\n",
    "* log(1) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701ed52-eba4-4d63-a9a3-0472e8c39eae",
   "metadata": {},
   "source": [
    "# 25.05.2023\n",
    "\n",
    "## WordSpace\n",
    "* **WordSpace** / matrix factorization or gradient descent or topic models\n",
    "* *gradient descent* = tends to work better with large data sets\n",
    "* *matrix factorization* = more accurate, more communly used for smaller data sets\n",
    "* *topic models*\n",
    "* comparing WordSpace vectors: cosine similarity or dot product (if dot product = 0 --> no similarities)\n",
    "* WordSpace based on counts\n",
    "\n",
    "## Word embedding learning = parameter estimation\n",
    "\n",
    "* embeddings (Learned by Matrix Factorization)\n",
    "* embeddings are \"learned\"\n",
    "\n",
    "### Homework 5:\n",
    "* pdf: \"Wortähnlichkeit\"\n",
    "* *Exercise 2.3*: silde 15/17\n",
    "* **argsort**: gives the position of the highest element, not the element --> output: array of the indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd8c3ee-c8f5-4ce9-bc7b-df368433a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23649080-f6ed-42d9-aace-b3efc01effb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Moodle Assignment: Matrix Factorisation (Abgabe am 1. Juni, 11:30)\n",
    "\n",
    "'''  a \td1 \td2 \td3\n",
    "sponge \t1 \t0 \t0\n",
    "dish \t1 \t0 \t0\n",
    "cloth \t0 \t1 \t0\n",
    "pool \t0 \t0 \t1 '''\n",
    "\n",
    "a_d2 = np.array([0, 0, 1, 0])\n",
    "a_d3 = np.array([0, 0, 0, 1])\n",
    "\n",
    "print(np.dot(a_d2, a_d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9530e69d-2b47-4960-975d-52d22d831d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2925\n"
     ]
    }
   ],
   "source": [
    "''' b \td1 \t    d2 \t    d 3\n",
    "sponge \t0.5 \t0.32 \t0.54\n",
    "dish \t0.22 \t0.41 \t0.15\n",
    "cloth \t-0.32 \t-0.12 \t0.11\n",
    "pool \t0.24 \t0.42 \t0.17'''\n",
    "\n",
    "b_d2 = np.array([0.32, 0.41, -0.12, 0.42])\n",
    "b_d3 = np.array([0.54, 0.15, 0.11, 0.17])\n",
    "\n",
    "print(np.dot(b_d2, b_d3))           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e09f1-6578-449b-a41e-f1236d1ae863",
   "metadata": {},
   "source": [
    "# 01.06.2023\n",
    "## Embeddings learned by Gradient Descent\n",
    "\n",
    "* GoogleNews embeddings\n",
    "\n",
    "### word2vec skipgram versions\n",
    "\n",
    "\"the cat **chases** the dog\" -->**chases** = w(t)\n",
    "\n",
    "### skipgram negative sampling (SGNS): objective\n",
    "\n",
    "### Embeddings via gradient descent\n",
    "\n",
    "### Visualization\n",
    "\n",
    "### FastText\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "## Implementation of Skipgram (Word2Vec); Using Word Vectors\n",
    "\n",
    "### Negative Log-likelihood\n",
    "x: word pair\n",
    "y: did word pair coocure?\n",
    "P(..) : dot product and sigmoid function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab71954-0dc8-4248-8c25-0b852014d1f2",
   "metadata": {},
   "source": [
    "# 06.06.2023\n",
    "* discuss past Moodle\n",
    "\n",
    "## Word2Vec (Implementation)\n",
    "\n",
    "word pair / x --> did the word pair occur together? / y\n",
    "\n",
    "* likelihood --> sigmoid function maps probability between 0 and 1\n",
    "\n",
    "* creation of negative word pairs\n",
    "* embedding matrices \n",
    "* Stochastic Gradient Descent --> a vector as large as your parameters\n",
    "\n",
    "**Questions:**\n",
    "* In which case does the update make the vectors of a word pair more similar? In which case more dissimilar?\n",
    "* In which case has the update a large effect? When does it have a small effect?\n",
    "* What are similarities and differences to the perceptron update?\n",
    "\n",
    "*Answers: slides 14/32*\n",
    "\n",
    "Looks like perceptron but weighted differently\n",
    "\n",
    "* Implementing Skipgram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2b768-be67-4b62-9c34-5806b5ef6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self, target_id, context_id, label, learning_rate):\n",
    "# TODO: update self.context_word_matrix[context_id]\n",
    "# TODO: update self.target_word_matrix[target_id]\n",
    "    v = self.context_word_matrix[context_id]\n",
    "    w = self.target_word_matrix[target_id]\n",
    "    \n",
    "    #Stochastic Gradient Descent formula\n",
    "    #prediction = sigmoid(v.dot(w)) --> implement sigmoid function if it doesn't exist \n",
    "    v_new = v + learning_rate*(label - prediction)*w\n",
    "    w_new = w + learning_rate*(label - prediction)*v #updating: use \"old\" v; don't use updated version to update\n",
    "    # necesarry to think about the changed numpy matrix, copy it if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9510e94e-0afb-4a49-a868-a4392a929c77",
   "metadata": {},
   "source": [
    "# 13.06.2023\n",
    "* discuss past programming exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a54e7-0333-486e-b277-1d8f89928ba9",
   "metadata": {},
   "source": [
    "# 15.06.2023\n",
    "## Using Word Vectors\n",
    "### Example: Word-Sentiment\n",
    "\n",
    "**Wort     Vektor                 Label**\n",
    "\n",
    "absurd   [-0.4, 0.2,0.2,. . . ] NEG\n",
    "\n",
    "accurate [-0.1,-1.2,0.1,. . . ] POS\n",
    "\n",
    "proper   [ 0.2,-0.1,0.2,. . . ] POS\n",
    "\n",
    "racist   [-0.5, 0.5,0.1,. . . ] NEG\n",
    "\n",
    "...\n",
    "\n",
    "* f(eature)1: positive (+) --> highest values associated with --> positive\n",
    "* f(eature)2: negative (-) --> highest values associated with --> negative\n",
    "* f(eature)3: neutral(~0) --> no correlation\n",
    "\n",
    "### Beispiel 2: Type-Prediction\n",
    "\n",
    "* order of words matters\n",
    "\n",
    "* Question Answering: include information about the tyoe of the entitiy (administrative area, actor)\n",
    "\n",
    "**Examples:** *Which administrative area does Kiel belong to? What actors starred in Gran Torino?*\n",
    "\n",
    "* Differences to word polarity prediction\n",
    "\n",
    "#### Classifiers\n",
    "* Multilabel: serveral labels possible at the same time\n",
    "* Multiclass: exactly one label is correct\n",
    "---\n",
    "## Large-scale pre-trained language models\n",
    "### Auto-regressive language models\n",
    "* GPT-3\n",
    "\n",
    "### Masked language models\n",
    "\n",
    "* often more practical but don't create text\n",
    "* often reconstruct already existing text or parts of texts, don't create new texts (works well at error detection)\n",
    "\n",
    "--\n",
    "\n",
    "**We have seen auto-regressive LM's**\n",
    "* context: previous words\n",
    "* predict: next word\n",
    "\n",
    "**Another type: masked LM's**\n",
    "* context: surrounding words\n",
    "* predict: masked word\n",
    "\n",
    "--\n",
    "\n",
    "#### BERT: Bidirectional Encoder Representations from Transformers\n",
    "\n",
    "* Masked language model\n",
    "* \"BERT as a black box\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37f29a-0169-47d5-8c12-2b2443f166aa",
   "metadata": {},
   "source": [
    "# 20.06.2023\n",
    "\n",
    "Renato Souza\n",
    "* session for questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec2703-2ab5-4833-adeb-51085494d100",
   "metadata": {},
   "source": [
    "# 23.06.2023\n",
    "## Transformer Language Models\n",
    "(some things part of the exam - ARLM, MLM)\n",
    "\n",
    "* start: BERT Training Phases\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480e2d5-3c4b-4f62-bd2f-65f5556cabae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d1c397-008b-4297-948d-c5af4c1ffa03",
   "metadata": {},
   "source": [
    "# 27.06.2023\n",
    "\n",
    "practice exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad75971-bda6-4a91-9b34-49a25c4aa62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
