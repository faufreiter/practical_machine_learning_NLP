{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment done by: Felix Aufreiter (1251759)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://communications.univie.ac.at/fileadmin/_processed_/csm_Uni_Logo_2016_2f47aacf37.jpg\" \n",
    "     alt=\"Logo Universität Wien\" \n",
    "     width=\"200\"/>\n",
    "\n",
    "# Practical Machine Learning for Natural Language Processing - 2023 SS  \n",
    "\n",
    "### Assigment 1 - Python for Poets  \n",
    "\n",
    "This assigment is an adaptation for Python of the original exercise [\"Unix for Poets\"](https://www.cs.upc.edu/~padro/Unixforpoets.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBR said Friday the global economic downturn so far has\n",
      "had\n",
      "little effect on its business but warned some projects on its books\n",
      "could be in jeopardy if the headwinds persist into next year.\n",
      "\n",
      "\"With the economic outlook remaining uncertain, it is possible\n",
      "that\n",
      "customers may cancel or delay projects that are under way,\" said\n",
      "William\n",
      "Utt, chief executive of the Houston-based engineering and\n",
      "construction\n",
      "giant and government contractor.\n",
      "\n",
      "He did not predict how much of the company's $15.3billion in\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "f = open('../practical_machine_learning_NLP/assignment/nyt_200811.txt', 'r')\n",
    "text = f.read()\n",
    "\n",
    "print(text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with files: **08_Data_Persistence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will solve the following exercises using **Pure Python** (only package \"string\" is allowed).  \n",
    "1. Count words in a text  \n",
    "2. Sort a list of words in various ways  \n",
    "   • ascii order   \n",
    "   • \"rhyming\" order   \n",
    "3. Extract useful info for a dictionary  \n",
    "4. Compute ngram statistics  \n",
    "5. Make a Concordance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Python String Methods https://www.w3schools.com/python/python_ref_string.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Count words in a text\n",
    "\n",
    "a. Output a list of words in the file along with their frequency counts (ignoring case).   \n",
    "b. Count how many unique words there are (ignoring case).    \n",
    "c. Check how common are all different sequences of vowels (e.g. the sequences \"ieu\" or just \"e\" in \"lieutenant\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Output a list of words in the file along with their frequency counts (ignoring case).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 3508213\n"
     ]
    }
   ],
   "source": [
    "# COUNT words of the text\n",
    "count = 0\n",
    "\n",
    "for line in text:\n",
    "    word = line.split(\" \")\n",
    "    count += len(word)\n",
    "  \n",
    "print(\"Words: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "\n",
    "for character in string.punctuation:\n",
    "    text_withoutpunct = text.replace(character, '')\n",
    "    \n",
    "# string --> strip.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kbr said friday the global economic downturn so far has\n",
      "had\n",
      "little effect on its business but warned some projects on its books\n",
      "could be in jeopardy if the headwinds persist into next year.\n",
      "\n",
      "\"with the economic outlook remaining uncertain, it is possible\n",
      "that\n",
      "customers may cancel or delay projects that are under way,\" said\n",
      "william\n",
      "utt, chief executive of the houston-based engineering and\n",
      "construction\n",
      "giant and government contractor.\n",
      "\n",
      "he did not predict how much of the company's $15.3billion in\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "#lowercase \n",
    "\n",
    "text_lower = text_withoutpunct.lower()\n",
    "print(text_lower[0:500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kbr', 'said', 'friday', 'the', 'global', 'economic', 'downturn', 'so', 'far', 'has', 'had', 'little', 'effect', 'on', 'its', 'business', 'but', 'warned', 'some', 'projects', 'on', 'its', 'books', 'could', 'be', 'in', 'jeopardy', 'if', 'the', 'headwinds', 'persist', 'into', 'next', 'year.', '\"with', 'the', 'economic', 'outlook', 'remaining', 'uncertain,', 'it', 'is', 'possible', 'that', 'customers', 'may', 'cancel', 'or', 'delay', 'projects', 'that', 'are', 'under', 'way,\"', 'said', 'william', 'utt,', 'chief', 'executive', 'of', 'the', 'houston-based', 'engineering', 'and', 'construction', 'giant', 'and', 'government', 'contractor.', 'he', 'did', 'not', 'predict', 'how', 'much', 'of', 'the', \"company's\", '$15.3billion', 'in', 'future', 'business', 'commitments', 'could', 'be', 'affected', 'but', 'downplayed', 'the', 'potential', 'of', 'any', 'significant', 'impact', 'as', '\"limited.\"', 'the', 'remarks', 'came', 'during']\n"
     ]
    }
   ],
   "source": [
    "#split text\n",
    "\n",
    "words = text_lower.split()\n",
    "print(words[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words = {} \n",
    "\n",
    "for word in words:\n",
    "            if word not in counted_words:\n",
    "                counted_words[word] = 1\n",
    "            else:\n",
    "                counted_words[word] += 1\n",
    "\n",
    "                \n",
    "#print(counted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 29333), ('a', 13109), ('to', 12770), ('of', 12521), ('and', 12134), ('in', 11043), ('that', 5675), ('for', 5072), ('on', 4177), ('is', 4176), ('he', 3824), ('with', 3475), ('was', 3405), ('at', 3040), ('as', 2963), ('his', 2761), ('it', 2718), ('have', 2409), ('but', 2397), ('be', 2383), ('by', 2334), ('said', 2204), ('has', 2166), ('are', 2154), ('from', 2069), ('an', 2030), ('not', 2005), ('who', 1785), ('they', 1739), ('this', 1625), ('had', 1565), ('--', 1552), ('their', 1489), ('i', 1424), ('about', 1394), ('or', 1345), ('will', 1340), ('more', 1292), ('were', 1275), ('one', 1201), ('would', 1172), ('new', 1170), ('we', 1151), ('when', 1133), ('been', 1127), ('said.', 1117), ('she', 1108), ('you', 1000), ('if', 975), ('her', 973)]\n"
     ]
    }
   ],
   "source": [
    "#sorted dictionary (descending)\n",
    "\n",
    "sorted_word_count = sorted(counted_words.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_word_count[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Count how many unique words there are (ignoring case).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in the file nyt_200811.txt: 54176\n"
     ]
    }
   ],
   "source": [
    "#create set\n",
    "unique_words = set()\n",
    "\n",
    "#adding words to set \"unique_words\"\n",
    "for word in words:\n",
    "    unique_words.add(word)\n",
    "    \n",
    "#count the number of \"unique_words\"\n",
    "number_unique_words = len(unique_words)\n",
    "print(\"Unique words in the file nyt_200811.txt:\", number_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Check how common are all different sequences of vowels (e.g. the sequences \"ieu\" or just \"e\" in \"lieutenant\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:#bfbfbf'> Additional</span> **links**: \n",
    "* count vowels https://www.geeksforgeeks.org/python-count-display-vowels-string/\n",
    "* Python regex https://www.w3schools.com/python/python_regex.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sorting and reversing lines of text\n",
    "\n",
    "a. Sort each line alphabetically (ignoring case).  \n",
    "b. Sort in numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  \n",
    "c. Alphabetically reverse sort (ignoring case).  \n",
    "d. Sort in reverse numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:#bfbfbf'> Additional</span> **links**: \n",
    "* https://www.learnbyexample.org/python-list-sort-method/\n",
    "* https://learnpython.com/blog/sort-alphabetically-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kbr said friday the global economic downturn so far has',\n",
       " 'had',\n",
       " 'little effect on its business but warned some projects on its books',\n",
       " 'could be in jeopardy if the headwinds persist into next year.',\n",
       " '',\n",
       " '\"with the economic outlook remaining uncertain, it is possible',\n",
       " 'that',\n",
       " 'customers may cancel or delay projects that are under way,\" said',\n",
       " 'william',\n",
       " 'utt, chief executive of the houston-based engineering and']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split text into lines\n",
    "text_lower_lines = text_lower.splitlines()\n",
    "text_lower_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort each line alphabetically (alphabetically or ASCII????)\n",
    "text_lower_lines.sort(reverse=False)\n",
    "text_lower_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ãº1.8',\n",
       " 'zwick,',\n",
       " 'zwick',\n",
       " 'zwerin,',\n",
       " 'zuttah',\n",
       " 'zutell:',\n",
       " 'zutell,',\n",
       " 'zutell',\n",
       " 'zurich.',\n",
       " 'zurich']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NO need to sort each word in every line alphabetically\n",
    "#Sort ONLY the order of the lines\n",
    "\n",
    "words.sort()\n",
    "words.reverse()\n",
    "words[0:10]\n",
    "# reverse numeric order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "\n",
    "#ASCII order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Alphabetically reverse sort (ignoring case).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Computing basic statistics\n",
    "\n",
    "a. Find the 50 most common words  \n",
    "b. Find the words in the NYT that end in \"zz\"  \n",
    "c. Count the lines, the words, and the characters  \n",
    "d. How many all uppercase words are there in this NYT file?  \n",
    "e, How many 4-letter words?  \n",
    "f. How many different words are there with no vowels?  \n",
    "g. **tricky:** How many “1 syllable” words are there?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 29333), ('a', 13109), ('to', 12770), ('of', 12521), ('and', 12134), ('in', 11043), ('that', 5675), ('for', 5072), ('on', 4177), ('is', 4176), ('he', 3824), ('with', 3475), ('was', 3405), ('at', 3040), ('as', 2963), ('his', 2761), ('it', 2718), ('have', 2409), ('but', 2397), ('be', 2383), ('by', 2334), ('said', 2204), ('has', 2166), ('are', 2154), ('from', 2069), ('an', 2030), ('not', 2005), ('who', 1785), ('they', 1739), ('this', 1625), ('had', 1565), ('--', 1552), ('their', 1489), ('i', 1424), ('about', 1394), ('or', 1345), ('will', 1340), ('more', 1292), ('were', 1275), ('one', 1201), ('would', 1172), ('new', 1170), ('we', 1151), ('when', 1133), ('been', 1127), ('said.', 1117), ('she', 1108), ('you', 1000), ('if', 975), ('her', 973)]\n"
     ]
    }
   ],
   "source": [
    "# a) Find the 50 most common words\n",
    "\n",
    "#sorted dictionary (descending)\n",
    "\n",
    "sorted_word_count = sorted(counted_words.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_word_count[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buzz',\n",
       " 'buzz',\n",
       " 'jazz',\n",
       " 'buzz',\n",
       " 'buzz',\n",
       " 'jazz',\n",
       " 'Jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'Buzz',\n",
       " 'Buzz',\n",
       " 'Buzz',\n",
       " 'Jazz',\n",
       " 'buzz',\n",
       " 'Jazz',\n",
       " 'pizazz',\n",
       " 'Buzz',\n",
       " 'buzz',\n",
       " 'Jazz',\n",
       " 'buzz']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Find the words in the NYT that end in \"zz\" \n",
    "\n",
    "re.findall(r\"\\b\\w*[z][z]\\b\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 70334\n",
      "Words: 509851\n",
      "Characters: 2596399\n"
     ]
    }
   ],
   "source": [
    "# c.) Count the lines, the words, and the characters.\n",
    "\n",
    "#lines\n",
    "count_lines = len(text_lower_lines) #lines were already created\n",
    "print(\"Lines:\",count_lines)\n",
    "\n",
    "#words\n",
    "count_words = len(words) #words were already used \n",
    "print(\"Words:\",count_words)\n",
    "\n",
    "#characters\n",
    "\n",
    "characters = list(text_withoutpunct.replace(\" \", \"\")) #using text without punctuaction and replacing blank spaces\n",
    "count_characters = len(characters)\n",
    "print(\"Characters:\",count_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8544"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d) How many all uppercase words are there in this NYT file?\n",
    "\n",
    "uppercase = re.findall(r\"\\b[A-Z]+\\b\", text)\n",
    "count_uppercase = len(uppercase)\n",
    "count_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88873"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e) How many 4-letter words?\n",
    "\n",
    "four_letter_words = re.findall(r\"\\b\\w\\w\\w\\w\\b\", text)\n",
    "count_flw = len(four_letter_words)\n",
    "count_flw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503463"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f) How many different words are there with no vowels?\n",
    "# Use y as a vowel??? \n",
    "\n",
    "without_vowels = re.findall(r\"\\b[^aeiouäöüyAEIOUÄÖÜY]+\\b\", text)\n",
    "\n",
    "without_vowels_count = len(without_vowels)\n",
    "without_vowels_count\n",
    "\n",
    "\n",
    "#without_vowels\n",
    "\n",
    "#CORRECT? --> Remove BLANK spaces!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "without_vowels1 = re.findall(r\"\\b[^aeiouäöüyAEIOUÄÖÜY]+\\b\", text)\n",
    "#without_vowels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g) tricky: How many “1 syllable” words are there? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4. Compute ngrams  \n",
    "\n",
    "a. Find the 10 most common bigrams  \n",
    "b. Find the 10 most common trigrams  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional information/sources: https://towardsdatascience.com/text-analysis-basics-in-python-443282942ec5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'the') : 3123\n",
      "('in', 'the') : 2727\n",
      "('to', 'the') : 1186\n",
      "('on', 'the') : 1144\n",
      "('for', 'the') : 934\n",
      "('and', 'the') : 845\n",
      "('in', 'a') : 832\n",
      "('at', 'the') : 762\n",
      "('to', 'be') : 714\n",
      "('with', 'the') : 602\n"
     ]
    }
   ],
   "source": [
    "# a) Find the 10 most common bigrams\n",
    "\n",
    "# words --> already used method: split + lower\n",
    "\n",
    "bigram_words = text_lower.split()\n",
    "\n",
    "#list for bigrams\n",
    "bigrams = []\n",
    "\n",
    "#for loop for bigrams\n",
    "for i in range(len(bigram_words)-1):\n",
    "    bigrams.append((bigram_words[i], bigram_words[i+1]))\n",
    "\n",
    "#count bigrams\n",
    "count_bigrams_list = {}\n",
    "for bigram in bigrams:\n",
    "    if bigram in count_bigrams_list:\n",
    "        count_bigrams_list[bigram] += 1\n",
    "    else:\n",
    "        count_bigrams_list[bigram] = 1\n",
    "\n",
    "#finding 10 most common bigrams\n",
    "bigrams_10 = sorted(count_bigrams_list.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in range(10):\n",
    "    print(bigrams_10[i][0], \":\", bigrams_10[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK-Test\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\faufr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', '``') 3651\n",
      "('of', 'the') 3091\n",
      "(',', \"''\") 2794\n",
      "('in', 'the') 2501\n",
      "('.', \"''\") 2407\n",
      "('.', 'The') 2193\n",
      "(',', 'the') 2092\n",
      "(',', 'and') 1924\n",
      "(',', 'a') 1303\n",
      "('to', 'the') 1172\n"
     ]
    }
   ],
   "source": [
    "#NLTK-Test\n",
    "nltk_tokens = nltk.word_tokenize(text) \n",
    "bigrams = list(nltk.bigrams(nltk_tokens))\n",
    "#bigrams\n",
    "frequence = nltk.FreqDist(bigrams)\n",
    "\n",
    "most_common = frequence.most_common(10)\n",
    "# 10 most_common\n",
    "for bigram, count in most_common:\n",
    "    print(bigram, count)\n",
    "    \n",
    "# DIFFERENT counts --> WHY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'of', 'the') : 223\n",
      "('a', 'lot', 'of') : 175\n",
      "('the', 'united', 'states') : 118\n",
      "('going', 'to', 'be') : 91\n",
      "('can', 'be', 'reached') : 91\n",
      "('as', 'well', 'as') : 90\n",
      "('be', 'reached', 'at') : 90\n",
      "('the', 'end', 'of') : 90\n",
      "('the', 'new', 'york') : 89\n",
      "('to', 'be', 'a') : 85\n"
     ]
    }
   ],
   "source": [
    "# b) Find the 10 most common TRIGRAMS\n",
    "\n",
    "# words --> already used method: split + lower\n",
    "\n",
    "trigram_words = text_lower.split()\n",
    "\n",
    "#list for trigrams\n",
    "trigrams = []\n",
    "\n",
    "#for loop: trigrams\n",
    "for t in range(len(trigram_words)-2):\n",
    "    trigrams.append((trigram_words[t], trigram_words[t+1], trigram_words[t+2]))\n",
    "\n",
    "#count trigrams\n",
    "count_trigrams_list = {}\n",
    "for trigram in trigrams:\n",
    "    if trigram in count_trigrams_list:\n",
    "        count_trigrams_list[trigram] += 1\n",
    "    else:\n",
    "        count_trigrams_list[trigram] = 1\n",
    "\n",
    "#finding 10 most common trigrams\n",
    "trigrams_10 = sorted(count_trigrams_list.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for t in range(10):\n",
    "    print(trigrams_10[t][0], \":\", trigrams_10[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('said', '.', '``') 648\n",
      "(',', \"''\", 'said') 631\n",
      "('.', '``', 'I') 593\n",
      "(',', \"''\", 'he') 447\n",
      "('.', '``', 'We') 418\n",
      "(\"''\", 'he', 'said') 349\n",
      "('he', 'said', '.') 303\n",
      "('.', '``', 'It') 281\n",
      "('.', \"''\", 'The') 246\n",
      "('.', '``', 'The') 242\n"
     ]
    }
   ],
   "source": [
    "#NLTK-Test: TRIGRAMS\n",
    "\n",
    "nltk_tokens_trigrams = nltk.word_tokenize(text) \n",
    "trigrams = list(nltk.trigrams(nltk_tokens_trigrams))\n",
    "#bigrams\n",
    "frequence_tri = nltk.FreqDist(trigrams)\n",
    "\n",
    "most_common_trigrams = frequence_tri.most_common(10)\n",
    "# 10 most_common\n",
    "for bigram, count in most_common_trigrams:\n",
    "    print(bigram, count)\n",
    "    \n",
    "# DIFFERENT counts AGAIN --> WHY? --> Text still in uppercase! (CHANGE!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Make a Concordance\n",
    "\n",
    "a. Create a concordance display for an arbitrary word. See the example below  \n",
    "\n",
    "![](../../Data/figs/Sample-concordance-lines-of-actually.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing regex https://regex101.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit – Secret Message\n",
    "+ The answers to the extra credit exercises will reveal a secret message.  \n",
    "+ We will be working with the following text file for these exercises:  \n",
    "[Link to Text](https://web.stanford.edu/class/cs124/lec/secret_ec.txt)  \n",
    "(No starter code in the Extra Credit)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 1\n",
    "• Find the 2 most common words in secret_ec.txt containing the letter e.  \n",
    "• Your answer will correspond to the first two words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 2\n",
    "• Find the 2 most common bigrams in secret_ec.txt where the second word in the bigram ends with a consonant.  \n",
    "• Your answer will correspond to the next four words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 3\n",
    "• Find all 5-letter-long words that only appear once in secret_ec.txt.   \n",
    "• Concatenate your result. This will be the final word of the secret message.  \n",
    "\n",
    "What is the secret message?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
