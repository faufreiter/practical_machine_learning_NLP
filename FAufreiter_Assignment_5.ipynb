{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment done by: Felix Aufreiter (1251759)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://communications.univie.ac.at/fileadmin/_processed_/csm_Uni_Logo_2016_2f47aacf37.jpg\" \n",
    "     alt=\"Logo Universität Wien\" \n",
    "     width=\"200\"/>\n",
    "\n",
    "# Practical Machine Learning for Natural Language Processing - 2023 SS  \n",
    "\n",
    "### Assigment 1 - Python for Poets  \n",
    "\n",
    "This assigment is an adaptation for Python of the original exercise [\"Unix for Poets\"](https://www.cs.upc.edu/~padro/Unixforpoets.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBR said Friday the global economic downturn so far has\n",
      "had\n",
      "little effect on its business but warned some projects on its books\n",
      "could be in jeopardy if the headwinds persist into next year.\n",
      "\n",
      "\"With the economic outlook remaining uncertain, it is possible\n",
      "that\n",
      "customers may cancel or delay projects that are under way,\" said\n",
      "William\n",
      "Utt, chief executive of the Houston-based engineering and\n",
      "construction\n",
      "giant and government contractor.\n",
      "\n",
      "He did not predict how much of the company's $15.3billion in\n",
      "fu\n"
     ]
    }
   ],
   "source": [
    "f = open('../practical_machine_learning_NLP/assignment/nyt_200811.txt', 'r')\n",
    "text = f.read()\n",
    "\n",
    "print(text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with files: **08_Data_Persistence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will solve the following exercises using **Pure Python** (only package \"string\" is allowed).  \n",
    "1. Count words in a text  \n",
    "2. Sort a list of words in various ways  \n",
    "   • ascii order   \n",
    "   • \"rhyming\" order   \n",
    "3. Extract useful info for a dictionary  \n",
    "4. Compute ngram statistics  \n",
    "5. Make a Concordance  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Python String Methods https://www.w3schools.com/python/python_ref_string.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Count words in a text\n",
    "\n",
    "a. Output a list of words in the file along with their frequency counts (ignoring case).   \n",
    "b. Count how many unique words there are (ignoring case).    \n",
    "c. Check how common are all different sequences of vowels (e.g. the sequences \"ieu\" or just \"e\" in \"lieutenant\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Output a list of words in the file along with their frequency counts (ignoring case).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 3508213\n"
     ]
    }
   ],
   "source": [
    "# COUNT words of the text\n",
    "count = 0\n",
    "\n",
    "for line in text:\n",
    "    word = line.split(\" \")\n",
    "    count += len(word)\n",
    "  \n",
    "print(\"Words: \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "\n",
    "for character in string.punctuation:\n",
    "    text = text.replace(character, '')\n",
    "    \n",
    "# string --> strip.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase \n",
    "\n",
    "text_lower = text.lower()\n",
    "#print(text_lower[0:500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split text\n",
    "\n",
    "words = text_lower.split()\n",
    "#print(words[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list123 = ['Hallo', 'adfadf', 'afhetheth', 'sohjkp', 'gpthhq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hallo', 'adfadf', 'afhetheth', 'gpthhq', 'sohjkp']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list123.sort()\n",
    "list123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words = {} \n",
    "\n",
    "for word in words:\n",
    "            if word not in counted_words:\n",
    "                counted_words[word] = 1\n",
    "            else:\n",
    "                counted_words[word] += 1\n",
    "\n",
    "                \n",
    "#print(counted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 29847), ('a', 13326), ('to', 12848), ('of', 12547), ('and', 12348), ('in', 11191), ('that', 5926), ('for', 5129), ('is', 4297), ('on', 4267), ('he', 3947), ('said', 3813), ('with', 3509), ('was', 3467), ('it', 3303), ('at', 3076), ('as', 3009), ('his', 2787), ('but', 2562), ('be', 2449), ('have', 2441), ('by', 2345), ('are', 2205), ('has', 2185), ('not', 2093), ('from', 2086), ('i', 2059), ('an', 2044), ('this', 1838), ('they', 1836), ('who', 1833), ('its', 1664), ('had', 1583), ('we', 1523), ('were', 1499), ('their', 1494), ('about', 1430), ('will', 1382), ('or', 1371), ('more', 1351), ('one', 1311), ('you', 1221), ('when', 1190), ('new', 1189), ('would', 1181), ('she', 1162), ('been', 1142), ('if', 1104), ('her', 1040), ('up', 1032)]\n"
     ]
    }
   ],
   "source": [
    "#sorted dictionary (descending)\n",
    "\n",
    "sorted_word_count = sorted(counted_words.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_word_count[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Count how many unique words there are (ignoring case).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in the file nyt_200811.txt: 32398\n"
     ]
    }
   ],
   "source": [
    "#create set\n",
    "unique_words = set()\n",
    "\n",
    "#adding words to set \"unique_words\"\n",
    "for word in words:\n",
    "    unique_words.add(word)\n",
    "    \n",
    "#count the number of \"unique_words\"\n",
    "number_unique_words = len(unique_words)\n",
    "print(\"Unique words in the file nyt_200811.txt:\", number_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Check how common are all different sequences of vowels (e.g. the sequences \"ieu\" or just \"e\" in \"lieutenant\")?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:#bfbfbf'> Additional</span> **links**: \n",
    "* count vowels https://www.geeksforgeeks.org/python-count-display-vowels-string/\n",
    "* Python regex https://www.w3schools.com/python/python_regex.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sorting and reversing lines of text\n",
    "\n",
    "a. Sort each line alphabetically (ignoring case).  \n",
    "b. Sort in numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  \n",
    "c. Alphabetically reverse sort (ignoring case).  \n",
    "d. Sort in reverse numeric ([ascii](https://python-reference.readthedocs.io/en/latest/docs/str/ASCII.html)) order.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='background:#bfbfbf'> Additional</span> **links**: \n",
    "* https://www.learnbyexample.org/python-list-sort-method/\n",
    "* https://learnpython.com/blog/sort-alphabetically-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kbr said friday the global economic downturn so far has',\n",
       " 'had',\n",
       " 'little effect on its business but warned some projects on its books',\n",
       " 'could be in jeopardy if the headwinds persist into next year',\n",
       " '',\n",
       " 'with the economic outlook remaining uncertain it is possible',\n",
       " 'that',\n",
       " 'customers may cancel or delay projects that are under way said',\n",
       " 'william',\n",
       " 'utt chief executive of the houstonbased engineering and']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split text into lines\n",
    "text_lower_lines = text_lower.splitlines()\n",
    "text_lower_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zutell of the office of insurance regulation noted a problem',\n",
       " 'zurich',\n",
       " 'zuma speaking in soweto seized on the notion of the dissidents',\n",
       " 'zorn buffalos dick jauron miamis tony sparano and yes even',\n",
       " 'zone with the giants fourth touchdown and a 287 lead the rest of',\n",
       " 'zone on first down moreno was stuffed on an uninspired run on',\n",
       " 'zone for a 137 lead',\n",
       " 'zone coaches such as the late bill walsh and the seahawks mike',\n",
       " 'zogby concedes that a letdown will come eventually',\n",
       " 'zobel nolan who has written more than 150 books was a senior']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort lines in reverse order (alphabetically or ASCII????)\n",
    "text_lower_lines.sort(reverse=True)\n",
    "text_lower_lines[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ãº18',\n",
       " 'zwick',\n",
       " 'zwick',\n",
       " 'zwerin',\n",
       " 'zuttah',\n",
       " 'zutell',\n",
       " 'zutell',\n",
       " 'zutell',\n",
       " 'zurich',\n",
       " 'zurich']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.sort()\n",
    "words.reverse()\n",
    "words[0:10]\n",
    "# reverse numeric order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "\n",
    "#ASCII order \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Computing basic statistics\n",
    "\n",
    "a. Find the 50 most common words  \n",
    "b. Find the words in the NYT that end in \"zz\"  \n",
    "c. Count the lines, the words, and the characters  \n",
    "d. How many all uppercase words are there in this NYT file?  \n",
    "e, How many 4-letter words?  \n",
    "f. How many different words are there with no vowels?  \n",
    "g. **tricky:** How many “1 syllable” words are there?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 29847), ('a', 13326), ('to', 12848), ('of', 12547), ('and', 12348), ('in', 11191), ('that', 5926), ('for', 5129), ('is', 4297), ('on', 4267), ('he', 3947), ('said', 3813), ('with', 3509), ('was', 3467), ('it', 3303), ('at', 3076), ('as', 3009), ('his', 2787), ('but', 2562), ('be', 2449), ('have', 2441), ('by', 2345), ('are', 2205), ('has', 2185), ('not', 2093), ('from', 2086), ('i', 2059), ('an', 2044), ('this', 1838), ('they', 1836), ('who', 1833), ('its', 1664), ('had', 1583), ('we', 1523), ('were', 1499), ('their', 1494), ('about', 1430), ('will', 1382), ('or', 1371), ('more', 1351), ('one', 1311), ('you', 1221), ('when', 1190), ('new', 1189), ('would', 1181), ('she', 1162), ('been', 1142), ('if', 1104), ('her', 1040), ('up', 1032)]\n"
     ]
    }
   ],
   "source": [
    "# a) Find the 50 most common words\n",
    "\n",
    "#sorted dictionary (descending)\n",
    "\n",
    "sorted_word_count = sorted(counted_words.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_word_count[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buzz',\n",
       " 'buzz',\n",
       " 'jazz',\n",
       " 'buzz',\n",
       " 'buzz',\n",
       " 'jazz',\n",
       " 'Jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'jazz',\n",
       " 'Buzz',\n",
       " 'Buzz',\n",
       " 'Buzz',\n",
       " 'Jazz',\n",
       " 'buzz',\n",
       " 'Jazz',\n",
       " 'pizazz',\n",
       " 'Buzz',\n",
       " 'buzz',\n",
       " 'Jazz',\n",
       " 'buzz']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Find the words in the NYT that end in \"zz\" \n",
    "\n",
    "re.findall(r\"\\b\\w*[z][z]\\b\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.) Count the lines, the words, and the characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d) USE regex???\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e) USE regex???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f) USE regex???\n",
    "\n",
    "#y auch Vokal teilweise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4. Compute ngrams  \n",
    "\n",
    "a. Find the 10 most common bigrams  \n",
    "b. Find the 10 most common trigrams  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional information/sources: https://towardsdatascience.com/text-analysis-basics-in-python-443282942ec5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'the') : 3144\n",
      "('in', 'the') : 2755\n",
      "('to', 'the') : 1193\n",
      "('on', 'the') : 1159\n",
      "('for', 'the') : 942\n",
      "('and', 'the') : 859\n",
      "('in', 'a') : 841\n",
      "('at', 'the') : 773\n",
      "('to', 'be') : 741\n",
      "('with', 'the') : 614\n"
     ]
    }
   ],
   "source": [
    "# a) Find the 10 most common bigrams\n",
    "\n",
    "# words --> already used method: split + lower\n",
    "\n",
    "bigram_words = text_lower.split()\n",
    "\n",
    "#list for bigrams\n",
    "bigrams = []\n",
    "\n",
    "#for loop for bigrams\n",
    "for i in range(len(bigram_words)-1):\n",
    "    bigrams.append((bigram_words[i], bigram_words[i+1]))\n",
    "\n",
    "#count bigrams\n",
    "count_bigrams_list = {}\n",
    "for bigram in bigrams:\n",
    "    if bigram in count_bigrams_list:\n",
    "        count_bigrams_list[bigram] += 1\n",
    "    else:\n",
    "        count_bigrams_list[bigram] = 1\n",
    "\n",
    "#finding 10 most common bigrams\n",
    "bigrams_10 = sorted(count_bigrams_list.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i in range(10):\n",
    "    print(bigrams_10[i][0], \":\", bigrams_10[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK-Test\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\faufr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('of', 'the') 3092\n",
      "('in', 'the') 2506\n",
      "('to', 'the') 1174\n",
      "('on', 'the') 1090\n",
      "('for', 'the') 884\n",
      "('and', 'the') 810\n",
      "('in', 'a') 756\n",
      "('to', 'be') 731\n",
      "('at', 'the') 678\n",
      "('with', 'the') 565\n"
     ]
    }
   ],
   "source": [
    "#NLTK-Test\n",
    "nltk_tokens = nltk.word_tokenize(text) \n",
    "bigrams = list(nltk.bigrams(nltk_tokens))\n",
    "#bigrams\n",
    "frequence = nltk.FreqDist(bigrams)\n",
    "\n",
    "most_common = frequence.most_common(10)\n",
    "# 10 most_common\n",
    "for bigram, count in most_common:\n",
    "    print(bigram, count)\n",
    "    \n",
    "# DIFFERENT counts --> WHY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'of', 'the') : 229\n",
      "('a', 'lot', 'of') : 199\n",
      "('the', 'united', 'states') : 181\n",
      "('going', 'to', 'be') : 93\n",
      "('as', 'well', 'as') : 92\n",
      "('can', 'be', 'reached') : 91\n",
      "('the', 'end', 'of') : 91\n",
      "('be', 'reached', 'at') : 90\n",
      "('the', 'new', 'york') : 89\n",
      "('to', 'be', 'a') : 85\n"
     ]
    }
   ],
   "source": [
    "# b) Find the 10 most common TRIGRAMS\n",
    "\n",
    "# words --> already used method: split + lower\n",
    "\n",
    "trigram_words = text_lower.split()\n",
    "\n",
    "#list for trigrams\n",
    "trigrams = []\n",
    "\n",
    "#for loop: trigrams\n",
    "for t in range(len(trigram_words)-2):\n",
    "    trigrams.append((trigram_words[t], trigram_words[t+1], trigram_words[t+2]))\n",
    "\n",
    "#count trigrams\n",
    "count_trigrams_list = {}\n",
    "for trigram in trigrams:\n",
    "    if trigram in count_trigrams_list:\n",
    "        count_trigrams_list[trigram] += 1\n",
    "    else:\n",
    "        count_trigrams_list[trigram] = 1\n",
    "\n",
    "#finding 10 most common trigrams\n",
    "trigrams_10 = sorted(count_trigrams_list.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for t in range(10):\n",
    "    print(trigrams_10[t][0], \":\", trigrams_10[t][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('one', 'of', 'the') 192\n",
      "('the', 'United', 'States') 175\n",
      "('a', 'lot', 'of') 172\n",
      "('going', 'to', 'be') 93\n",
      "('as', 'well', 'as') 92\n",
      "('can', 'be', 'reached') 91\n",
      "('be', 'reached', 'at') 90\n",
      "('the', 'end', 'of') 89\n",
      "('to', 'be', 'a') 85\n",
      "('the', 'University', 'of') 83\n"
     ]
    }
   ],
   "source": [
    "#NLTK-Test: TRIGRAMS\n",
    "\n",
    "nltk_tokens_trigrams = nltk.word_tokenize(text) \n",
    "trigrams = list(nltk.trigrams(nltk_tokens_trigrams))\n",
    "#bigrams\n",
    "frequence_tri = nltk.FreqDist(trigrams)\n",
    "\n",
    "most_common_trigrams = frequence_tri.most_common(10)\n",
    "# 10 most_common\n",
    "for bigram, count in most_common_trigrams:\n",
    "    print(bigram, count)\n",
    "    \n",
    "# DIFFERENT counts AGAIN --> WHY?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5. Make a Concordance\n",
    "\n",
    "a. Create a concordance display for an arbitrary word. See the example below  \n",
    "\n",
    "![](../../Data/figs/Sample-concordance-lines-of-actually.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing regex https://regex101.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit – Secret Message\n",
    "+ The answers to the extra credit exercises will reveal a secret message.  \n",
    "+ We will be working with the following text file for these exercises:  \n",
    "[Link to Text](https://web.stanford.edu/class/cs124/lec/secret_ec.txt)  \n",
    "(No starter code in the Extra Credit)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 1\n",
    "• Find the 2 most common words in secret_ec.txt containing the letter e.  \n",
    "• Your answer will correspond to the first two words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 2\n",
    "• Find the 2 most common bigrams in secret_ec.txt where the second word in the bigram ends with a consonant.  \n",
    "• Your answer will correspond to the next four words of the secret message.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extra Credit Exercise 3\n",
    "• Find all 5-letter-long words that only appear once in secret_ec.txt.   \n",
    "• Concatenate your result. This will be the final word of the secret message.  \n",
    "\n",
    "What is the secret message?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
